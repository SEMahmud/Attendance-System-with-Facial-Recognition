{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgRaihan = face_recognition.load_image_file('ImagesBasic/Raihan Sikdar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(imgRaihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[222 222 224]\n",
      "  [221 221 223]\n",
      "  [221 221 223]\n",
      "  ...\n",
      "  [166 161 158]\n",
      "  [166 161 158]\n",
      "  [166 161 158]]\n",
      "\n",
      " [[222 222 224]\n",
      "  [221 221 223]\n",
      "  [221 221 223]\n",
      "  ...\n",
      "  [166 161 158]\n",
      "  [166 161 158]\n",
      "  [166 161 158]]\n",
      "\n",
      " [[222 222 224]\n",
      "  [221 221 223]\n",
      "  [221 221 223]\n",
      "  ...\n",
      "  [166 161 158]\n",
      "  [166 161 158]\n",
      "  [166 161 158]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[181 178 185]\n",
      "  [167 168 173]\n",
      "  [133 138 142]\n",
      "  ...\n",
      "  [ 73  77  78]\n",
      "  [ 72  76  77]\n",
      "  [ 70  74  75]]\n",
      "\n",
      " [[167 164 171]\n",
      "  [158 157 163]\n",
      "  [129 134 138]\n",
      "  ...\n",
      "  [ 73  77  78]\n",
      "  [ 72  76  77]\n",
      "  [ 71  75  76]]\n",
      "\n",
      " [[135 130 137]\n",
      "  [137 136 142]\n",
      "  [120 125 129]\n",
      "  ...\n",
      "  [ 72  76  77]\n",
      "  [ 72  76  77]\n",
      "  [ 72  76  77]]]\n"
     ]
    }
   ],
   "source": [
    "print(imgRaihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgRaihan= cv2.cvtColor(imgRaihan, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img(imgRaihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTest = face_recognition.load_image_file('ImagesBasic/Kazi Sarwar.jpg')\n",
    "imgTest = cv2.cvtColor(imgTest, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceLoc = face_recognition.face_locations(imgRaihan)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(faceLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faceLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 365, 489, 142)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceLoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeRaihan = face_recognition.face_encodings(imgRaihan)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encodeRaihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.size(encodeRaihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11152276,  0.01487775,  0.05837865, -0.08818498, -0.1157174 ,\n",
       "       -0.04168291, -0.02177132, -0.07131764,  0.0783496 , -0.09079588,\n",
       "        0.19187057, -0.05218456, -0.23001696, -0.08310684,  0.0942738 ,\n",
       "        0.11147951, -0.07297697, -0.06654717, -0.07549662, -0.08912263,\n",
       "       -0.02642377,  0.0138378 ,  0.06904305,  0.03635114, -0.14288174,\n",
       "       -0.40147462, -0.07736941, -0.07788914, -0.01140768, -0.05687096,\n",
       "        0.00584533,  0.1355065 , -0.11836389,  0.01105282,  0.00273836,\n",
       "        0.13432072, -0.12014921, -0.11266108,  0.22193909, -0.02258046,\n",
       "       -0.13957576, -0.11301309,  0.05821356,  0.20149903,  0.17826621,\n",
       "        0.00651874,  0.08216521,  0.00701172,  0.07142571, -0.25086582,\n",
       "        0.09998637,  0.0880075 ,  0.04105217,  0.01430514,  0.18183737,\n",
       "       -0.12380473,  0.03602912,  0.05296203, -0.14131673, -0.01319744,\n",
       "       -0.00088623, -0.03028458, -0.05925829, -0.08739624,  0.26623783,\n",
       "        0.14376472, -0.10926998, -0.03379424,  0.09704405, -0.15143897,\n",
       "       -0.06542951,  0.03249428, -0.13049182, -0.16083604, -0.31963524,\n",
       "        0.01358557,  0.30201241,  0.17863263, -0.17289744,  0.01499785,\n",
       "       -0.0135929 , -0.03686927,  0.15476285,  0.05019547, -0.11007621,\n",
       "       -0.00588731, -0.08924457,  0.03579161,  0.16983552, -0.02241842,\n",
       "       -0.09073771,  0.19449091,  0.00646887,  0.0501549 ,  0.0390351 ,\n",
       "       -0.01612986, -0.05740551, -0.05366078, -0.1001811 , -0.01552722,\n",
       "        0.1711735 , -0.09175971,  0.00169519,  0.12933707, -0.19667526,\n",
       "        0.10721631, -0.00807911,  0.00328428,  0.05304821,  0.00600455,\n",
       "       -0.20252305, -0.04552127,  0.12620138, -0.24146783,  0.09190247,\n",
       "        0.14564241, -0.06717329,  0.13969155,  0.13250549,  0.05024283,\n",
       "       -0.02567862, -0.01831374, -0.12815006, -0.03979246,  0.09336329,\n",
       "        0.05689597,  0.07187737,  0.05970477])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodeRaihan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[224, 222, 222],\n",
       "        [223, 221, 221],\n",
       "        [223, 221, 221],\n",
       "        ...,\n",
       "        [158, 161, 166],\n",
       "        [158, 161, 166],\n",
       "        [158, 161, 166]],\n",
       "\n",
       "       [[224, 222, 222],\n",
       "        [223, 221, 221],\n",
       "        [223, 221, 221],\n",
       "        ...,\n",
       "        [158, 161, 166],\n",
       "        [158, 161, 166],\n",
       "        [158, 161, 166]],\n",
       "\n",
       "       [[224, 222, 222],\n",
       "        [223, 221, 221],\n",
       "        [223, 221, 221],\n",
       "        ...,\n",
       "        [158, 161, 166],\n",
       "        [158, 161, 166],\n",
       "        [158, 161, 166]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[185, 178, 181],\n",
       "        [173, 168, 167],\n",
       "        [142, 138, 133],\n",
       "        ...,\n",
       "        [ 78,  77,  73],\n",
       "        [ 77,  76,  72],\n",
       "        [ 75,  74,  70]],\n",
       "\n",
       "       [[171, 164, 167],\n",
       "        [163, 157, 158],\n",
       "        [138, 134, 129],\n",
       "        ...,\n",
       "        [ 78,  77,  73],\n",
       "        [ 77,  76,  72],\n",
       "        [ 76,  75,  71]],\n",
       "\n",
       "       [[137, 130, 135],\n",
       "        [142, 136, 137],\n",
       "        [129, 125, 120],\n",
       "        ...,\n",
       "        [ 77,  76,  72],\n",
       "        [ 77,  76,  72],\n",
       "        [ 77,  76,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(imgRaihan, (faceLoc[3], faceLoc[0]), (faceLoc[1], faceLoc[2]), (255, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        ...,\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250]],\n",
       "\n",
       "       [[250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        ...,\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250]],\n",
       "\n",
       "       [[250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        ...,\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250],\n",
       "        [250, 250, 250]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 96, 104, 103],\n",
       "        [ 96, 104, 103],\n",
       "        [ 96, 104, 103],\n",
       "        ...,\n",
       "        [  1,   1,   1],\n",
       "        [  1,   1,   1],\n",
       "        [  1,   1,   1]],\n",
       "\n",
       "       [[ 95, 103, 102],\n",
       "        [ 95, 103, 102],\n",
       "        [ 95, 103, 102],\n",
       "        ...,\n",
       "        [  1,   1,   1],\n",
       "        [  1,   1,   1],\n",
       "        [  1,   1,   1]],\n",
       "\n",
       "       [[ 95, 103, 102],\n",
       "        [ 95, 103, 102],\n",
       "        [ 95, 103, 102],\n",
       "        ...,\n",
       "        [  1,   1,   1],\n",
       "        [  1,   1,   1],\n",
       "        [  1,   1,   1]]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceLocTest = face_recognition.face_locations(imgTest)[0]\n",
    "encodeTest = face_recognition.face_encodings(imgTest)[0]\n",
    "cv2.rectangle(imgTest, (faceLocTest[3], faceLocTest[0]), (faceLocTest[1], faceLocTest[2]), (255, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = face_recognition.compare_faces([encodeRaihan], encodeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(results))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.bool_"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDis = face_recognition.face_distance([encodeRaihan], encodeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(faceDis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63218516])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faceDis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
